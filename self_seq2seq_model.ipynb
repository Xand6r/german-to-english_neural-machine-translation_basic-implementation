{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ===============implementation of a seq2seq machine translator from german to english======================================#\n",
    "# ================input (source_data) is in german and output(target is in english)=========================================#\n",
    "# ================ we are operating on time major basis ====================================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# defination of global variables\n",
    "number_of_sentences_to_read=50000\n",
    "max_input_length=41\n",
    "enc_time_step=41\n",
    "dec_time_step=61\n",
    "batch_size=18\n",
    "num_units=128\n",
    "max_output_length=61\n",
    "vocabulary_size=50000\n",
    "decoder_type=\"basic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "read in source vocabulary\n",
      "[('<unk>', 0), ('<s>', 1), ('</s>', 2), (',', 3), ('.', 4), ('die', 5), ('der', 6), ('und', 7), ('in', 8), ('zu', 9)]\n",
      "[(0, '<unk>'), (1, '<s>'), (2, '</s>'), (3, ','), (4, '.'), (5, 'die'), (6, 'der'), (7, 'und'), (8, 'in'), (9, 'zu')]\n",
      "vocabulary length: 50000\n",
      "\n",
      "read in target vocabulary\n",
      "[('<unk>', 0), ('<s>', 1), ('</s>', 2), ('the', 3), (',', 4), ('.', 5), ('of', 6), ('and', 7), ('to', 8), ('in', 9)]\n",
      "[(0, '<unk>'), (1, '<s>'), (2, '</s>'), (3, 'the'), (4, ','), (5, '.'), (6, 'of'), (7, 'and'), (8, 'to'), (9, 'in')]\n",
      "vocabulary length: 50000\n"
     ]
    }
   ],
   "source": [
    "# step 1- read in in of words vocabularies from the raw-dataset\n",
    "\n",
    "source_dictionary=dict()\n",
    "target_dictionary=dict()\n",
    "# read in the vocabulary of the source\n",
    "with open(r\"seq2seq\\vocab.50k.de\",encoding=\"utf-8\") as f:\n",
    "    for source_row in f:\n",
    "        source_dictionary[source_row[:-1]]=len(source_dictionary)# indexing up to -1 because it ends with a new line we dont want\n",
    "reverse_source_dictionary=dict(zip(source_dictionary.values(),source_dictionary.keys()))\n",
    "\n",
    "print(\"\\nread in source vocabulary\")\n",
    "print(list(source_dictionary.items())[:10])\n",
    "print(list(reverse_source_dictionary.items())[:10])\n",
    "print(\"vocabulary length:\",len(source_dictionary))\n",
    "        \n",
    "# read in the vocabulary of the target\n",
    "with open(r\"seq2seq\\vocab.50k.en\",encoding=\"utf-8\") as f:\n",
    "    for target_row in f:\n",
    "        target_dictionary[target_row[:-1]]=len(target_dictionary)# indexing up to -1 because it ends with a new line we dont want\n",
    "reverse_target_dictionary=dict(zip(target_dictionary.values(),target_dictionary.keys()))\n",
    "\n",
    "print(\"\\nread in target vocabulary\")\n",
    "print(list(target_dictionary.items())[:10])\n",
    "print(list(reverse_target_dictionary.items())[:10])\n",
    "print(\"vocabulary length:\",len(target_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example translations:\n",
      " 0 : Heute verstehen sich QuarkXPress ® 8 , Photoshop ® und Illustrator ® besser als jemals zuvor . Dank HTML und CSS ­ können Anwender von QuarkXPress inzwischen alle Medien bedienen , und das unabhängig von Anwendungen der Adobe ® Creative Suite ® wie Adobe Flash ® ( SWF ) und Adobe Dreamweaver ® .\n",
      " \n",
      "\n",
      " 0 : Today , QuarkXPress ® 8 has tighter integration with Photoshop ® and Illustrator ® than ever before , and through standards like HTML and CSS , QuarkXPress users can publish across media both independently and alongside Adobe ® Creative Suite ® applications like Adobe Flash ® ( SWF ) and Adobe Dreamweaver ® .\n",
      " \n",
      "\n",
      " 10000 : Es existieren Busverbindungen in nahezu jeden Ort der Provence ( eventuell mit Umsteigen in Aix ##AT##-##AT## en ##AT##-##AT## Provence ) , allerdings sollte beachtet werden , dass die letzten Busse abends ca. um 19 Uhr fahren .\n",
      " \n",
      "\n",
      " 10000 : As always in France those highways are expensive but practical , comfortable and fast .\n",
      " \n",
      "\n",
      " 20000 : Es war staubig , das Bad schmutzig . Sogar die Beleuchtung an der Wand im Flur ( Seitengebäude ) war richtig verstaubt .\n",
      " \n",
      "\n",
      " 20000 : It was rather old fashioned in the decoration .\n",
      " \n",
      "\n",
      " 30000 : Auch ist , so denkt Dr. Gutherz , bereits die erste Seite sehr viel versprechend , da sie eine Definition des klinischen Psychotrauma ##AT##-##AT## Begriffes enthält , der er gänzlich zustimmen kann .\n",
      " \n",
      "\n",
      " 30000 : At the rhetorical climax of this summary , Dr Goodheart comes across some sentences expressed with great pathos .\n",
      " \n",
      "\n",
      " 40000 : Bei einer digitalen Bildkette wird das Intensitätssignal für jedes Pixel ohne analoge Zwischenschritte direkt in der Detektoreinheit digitalisiert , d.h. in Zahlen umgewandelt .\n",
      " \n",
      "\n",
      " 40000 : A digital image chain is an image chain that is equipped with a digital detector instead of an analogue one .\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# step 2- read in the dataset for both the source and target sequence\n",
    "# input->german output(target)->english\n",
    "input_dataset=[]\n",
    "output_dataset=[]\n",
    "\n",
    "with open(r\"seq2seq\\train.de\",encoding=\"utf-8\") as f:\n",
    "    for index_of_row_read,input_row in enumerate(f):\n",
    "        if index_of_row_read<50: #because there are some errors in translation for the first few lines\n",
    "            continue\n",
    "        if index_of_row_read>number_of_sentences_to_read:\n",
    "            break\n",
    "        input_dataset.append(input_row)\n",
    "\n",
    "        \n",
    "with open(r\"seq2seq\\train.en\",encoding=\"utf-8\") as f:\n",
    "    for index_of_row_read,target_row in enumerate(f):\n",
    "        if index_of_row_read<50:\n",
    "            continue\n",
    "        if index_of_row_read>number_of_sentences_to_read:\n",
    "            break\n",
    "        output_dataset.append(target_row)\n",
    "\n",
    "print(\"example translations:\")\n",
    "for i in range(0,number_of_sentences_to_read,10000):\n",
    "    print(\"\",i,\":\",input_dataset[i],\"\\n\")\n",
    "    print(\"\",i,\":\",output_dataset[i],\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Source\n",
      "average length 23.1045624712\n",
      "standard deviation 12.6389970633\n",
      "\n",
      "Target\n",
      "average length 25.3302236191\n",
      "standard deviation 13.8682905263\n"
     ]
    }
   ],
   "source": [
    "# step-4 tokenize the word\n",
    "def tokenize_sentence(sentence,is_source):\n",
    "    sentence=sentence.replace(\".\",\" .\")\n",
    "    sentence=sentence.replace(\",\",\" ,\")\n",
    "    sentence=sentence.replace(\"\\n\",\" \")\n",
    "    \n",
    "    sentence_tokens=sentence.split()\n",
    "    \n",
    "    for index,token in enumerate(sentence_tokens):\n",
    "        if is_source:\n",
    "            if token not in source_dictionary:\n",
    "                sentence_tokens[index]=\"<unk>\"\n",
    "        else:\n",
    "            if token not in target_dictionary:\n",
    "                sentence_tokens[index]=\"<unk>\"\n",
    "    return sentence_tokens\n",
    "\n",
    "# computing some statistics\n",
    "source_lengths=[]\n",
    "target_lengths=[]\n",
    "\n",
    "for source_word,target_word in zip(input_dataset,output_dataset):\n",
    "    source_lengths.append(len(tokenize_sentence(source_word,True)))\n",
    "    target_lengths.append(len(tokenize_sentence(target_word,False)))\n",
    "    \n",
    "print(\"\\nSource\")\n",
    "print(\"average length\",np.mean(source_lengths))\n",
    "print(\"standard deviation\",np.std(source_lengths))\n",
    "\n",
    "print(\"\\nTarget\")\n",
    "print(\"average length\",np.mean(target_lengths))\n",
    "print(\"standard deviation\",np.std(target_lengths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing the data\n",
      "sample data\n",
      "<s> Je mehr Zeit wir mit Gilad und dem Rest des Teams in Israel verbracht haben ( um nicht den lauten Hahn zu erwähnen der <unk> bei denen über den Campus <unk> ) desto überzeugter waren wir – zusammen können wir mehr bewegen .\tof length 41\n",
      "</s> The more time we spent with Gilad as well as the rest of the team in Israel ( not to mention the very loud <unk> that runs around in their campus ) , the more convinced we all became - we ’ ll be better off together . </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\tof length 50\n"
     ]
    }
   ],
   "source": [
    "# step-4 preprocess the text and add extra pad tokens to make them of equal lengths\n",
    "print(\"preprocessing the data\")\n",
    "train_inputs=[]\n",
    "train_outputs=[]\n",
    "\n",
    "train_inputs_lengths=[]\n",
    "train_outputs_lengths=[]\n",
    "\n",
    "\n",
    "for train_input,train_output in zip(input_dataset,output_dataset):\n",
    "    num_train_input,num_train_output=[],[]\n",
    "    tokenized_input=tokenize_sentence(train_input,True)\n",
    "    tokenized_output=tokenize_sentence(train_output,False)\n",
    "    \n",
    "    #for input data     \n",
    "    for token in tokenized_input:\n",
    "        num_train_input.append(source_dictionary[token])\n",
    "    num_train_input.insert(0,source_dictionary[\"<s>\"])\n",
    "    \n",
    "    train_inputs_lengths.append(min(len(num_train_input)+1,max_input_length))\n",
    "    if len(num_train_input)+1<max_input_length:\n",
    "        num_train_input.extend([source_dictionary[\"</s>\"]]*(max_input_length-(len(tokenized_input)+1)))\n",
    "        \n",
    "    elif len(num_train_input)+1<max_input_length:\n",
    "        num_train_input=num_train_input[:max_input_length]\n",
    "       \n",
    "    train_inputs.append(num_train_input)\n",
    "#     for output data\n",
    "    for token in tokenized_output:\n",
    "        num_train_output.append(target_dictionary[token])\n",
    "    num_train_output.insert(0,target_dictionary[\"</s>\"])\n",
    "    \n",
    "    train_outputs_lengths.append(min(len(num_train_output)+1,max_output_length))\n",
    "    if len(num_train_output)+1<max_output_length:\n",
    "        num_train_output.extend([target_dictionary[\"</s>\"]]*(max_output_length-(len(tokenized_output)+1)))\n",
    "        \n",
    "    elif len(num_train_output)+1>max_output_length:\n",
    "        num_train_output=num_train_output[:max_output_length]\n",
    "        \n",
    "    train_outputs.append(num_train_output)\n",
    "print(\"sample data\")\n",
    "print(\" \".join([reverse_source_dictionary[w] for w in train_inputs[500]])+\"\\tof length\",train_inputs_lengths[500])\n",
    "print(\" \".join([reverse_target_dictionary[w] for w in train_outputs[500]])+ \"\\tof length\",train_outputs_lengths[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample generated data\n",
      "\n",
      "</s> Today , QuarkXPress ® 8 has tighter integration with Photoshop ® and Illustrator ® than ever before , and through standards like HTML and CSS , QuarkXPress users can publish across media both independently and alongside Adobe ® Creative Suite ® applications like Adobe Flash ® ( SWF ) and Adobe Dreamweaver ® . </s> </s> </s> </s> </s>\n",
      "\n",
      "<s> Heute verstehen sich QuarkXPress ® 8 , Photoshop ® und Illustrator ® besser als jemals zuvor . Dank HTML und CSS ­ können Anwender von QuarkXPress inzwischen alle Medien bedienen , und das unabhängig von Anwendungen der Adobe <s> Heute verstehen sich QuarkXPress ® 8 , Photoshop ® und Illustrator ® besser als jemals zuvor . Dank HTML und\n"
     ]
    }
   ],
   "source": [
    "# step-5 create a data batch generator which uses time major i.e [time_step*batch_size]\n",
    "\n",
    "class DataGeneratorMT(object):\n",
    "    def __init__(self,batch_size,is_source):\n",
    "        self._batch_size=batch_size\n",
    "        self._cursors=[0]*batch_size\n",
    "        self._is_source=is_source\n",
    "        if is_source:\n",
    "            self._max_length=41\n",
    "        else:\n",
    "            self._max_length=61\n",
    "        \n",
    "    def next_batch(self,data_indexes):\n",
    "        batch_output=[0]*self._batch_size\n",
    "        batch_label=[0]*self._batch_size\n",
    "        \n",
    "        for i,data_index in enumerate(data_indexes):\n",
    "            if self._is_source:\n",
    "                sent_text=train_inputs[data_index]\n",
    "            else:\n",
    "                sent_text=train_outputs[data_index]\n",
    "            batch_output[i]=sent_text[self._cursors[i]]\n",
    "            batch_label[i]=sent_text[self._cursors[i]+1]\n",
    "            \n",
    "            self._cursors[i]=(self._cursors[i]+1)%(self._max_length-2)\n",
    "        return batch_output,batch_label\n",
    "    \n",
    "    def reset_cursor(self):\n",
    "        self._cursors=[0]*self._batch_size\n",
    "        \n",
    "    def unroll_batches(self,unroll_length,data_indexes):\n",
    "        self.reset_cursor()\n",
    "        batch_outputs,batch_labels,batch_lengths=[],[],[]\n",
    "        \n",
    "        for ui in range(unroll_length):\n",
    "            batch_output,batch_label=self.next_batch(data_indexes)\n",
    "            batch_outputs.append(batch_output)\n",
    "            batch_labels.append(batch_label)\n",
    "        \n",
    "        if self._is_source:\n",
    "            batch_lengths=np.array(train_inputs_lengths)[data_indexes]\n",
    "        else:\n",
    "            batch_lengths=np.array(train_outputs_lengths)[data_indexes]\n",
    "        \n",
    "        return batch_outputs,batch_labels,data_indexes,batch_lengths\n",
    "    \n",
    "print(\"sample generated data\\n\")\n",
    "dt=DataGeneratorMT(1,False)\n",
    "data,_,_,_=dt.unroll_batches(60,[0])\n",
    "print(\" \".join([reverse_target_dictionary[datum] for datum in np.array(data).reshape(-1)]))\n",
    "\n",
    "print()\n",
    "dt=DataGeneratorMT(1,True)\n",
    "data,_,_,_=dt.unroll_batches(60,[0])\n",
    "print(\" \".join([reverse_source_dictionary[datum] for datum in np.array(data).reshape(-1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constuction of placeholders of the graph\n",
    "tf.reset_default_graph()\n",
    "with tf.name_scope(\"input_placeholders\"):\n",
    "    enc_train_inputs=tf.placeholder(shape=[enc_time_step,batch_size],dtype=tf.int32)\n",
    "    enc_sequence_lengths=tf.placeholder(shape=[batch_size],dtype=tf.int32)\n",
    "    dec_train_inputs=tf.placeholder(shape=[dec_time_step,batch_size],dtype=tf.int32)\n",
    "    dec_train_labels=tf.placeholder(shape=[dec_time_step,batch_size],dtype=tf.int32)\n",
    "    dec_labels_mask=tf.placeholder(shape=[dec_time_step,batch_size],dtype=tf.float32)\n",
    "\n",
    "with tf.name_scope(\"embeddings\"):\n",
    "    enc_embeddings=tf.convert_to_tensor(np.load(r\"./seq2seq/de-embeddings.npy\"))\n",
    "    dec_embeddings=tf.convert_to_tensor(np.load(r\"./seq2seq/en-embeddings.npy\"))\n",
    "\n",
    "with tf.name_scope(\"input_variables\"):\n",
    "    enc_emb_inputs=tf.nn.embedding_lookup(enc_embeddings,enc_train_inputs)\n",
    "    dec_emb_inputs=tf.nn.embedding_lookup(dec_embeddings,dec_train_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defination of encoder\n",
    "basic_cell=tf.nn.rnn_cell.BasicLSTMCell(num_units=num_units)\n",
    "\n",
    "initial_state=basic_cell.zero_state(batch_size,dtype=tf.float32)\n",
    "\n",
    "encoder_outputs,encoder_states=tf.nn.dynamic_rnn(\n",
    "    basic_cell,enc_emb_inputs,initial_state=initial_state\n",
    "    ,dtype=tf.float32,time_major=True,sequence_length=enc_sequence_lengths\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defination of decoder\n",
    "basic_decoder_cell=tf.nn.rnn_cell.BasicLSTMCell(num_units=num_units)\n",
    "training_helper=tf.contrib.seq2seq.TrainingHelper(dec_emb_inputs,sequence_length=[max_output_length]*batch_size,time_major=True)\n",
    "output_layer=tf.layers.Dense(units=vocabulary_size)\n",
    "\n",
    "if decoder_type==\"basic\":\n",
    "    decoder=tf.contrib.seq2seq.BasicDecoder(basic_decoder_cell,training_helper,initial_state=encoder_states,output_layer=output_layer)\n",
    "    \n",
    "if decoder_type==\"attention\":\n",
    "    decoder=tf.contrib.seq2seq.BahdanauAttention(basic_decoder_cell,training_helper,initial_state=encoder_states,output_layer=output_layer)\n",
    "\n",
    "outputs,_,_=tf.contrib.seq2seq.dynamic_decode(decoder,output_time_major=True,swap_memory=True)\n",
    "prediction=outputs.sample_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss \n",
    "xentropy=tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    labels=dec_train_labels,logits=outputs.rnn_output\n",
    ")\n",
    "loss=(tf.reduce_sum(xentropy*dec_labels_mask))/(batch_size*61)\n",
    "prediction=outputs.sample_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1711: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "# optimization\n",
    "\n",
    "# creating a learning rate decay\n",
    "global_step=tf.Variable(0,trainable=False)\n",
    "inc_global_step=tf.assign(global_step,global_step+1)\n",
    "learning_rate=tf.train.exponential_decay(0.001,global_step,decay_steps=10,decay_rate=0.9,staircase=True)\n",
    "\n",
    "# using two different optimization algorithms\n",
    "# using gradient clipping to prevent gradient explosion\n",
    "adam_optimizer=tf.train.AdamOptimizer(learning_rate)\n",
    "adam_grad,variable_name=zip(*adam_optimizer.compute_gradients(loss))\n",
    "clipped_grad,_=tf.clip_by_global_norm(adam_grad,25.0)\n",
    "adam_optimize=adam_optimizer.apply_gradients(zip(clipped_grad,variable_name))\n",
    "\n",
    "sgd_optimizer=tf.train.GradientDescentOptimizer(learning_rate)\n",
    "sgd_grad,variable_name1=zip(*sgd_optimizer.compute_gradients(loss))\n",
    "clipped_grad1,_=tf.clip_by_global_norm(sgd_grad,25.0)\n",
    "sgd_optimize=sgd_optimizer.apply_gradients(zip(clipped_grad1,variable_name1))\n",
    "\n",
    "sess=tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started_training\n",
      "\t\t\tstep:0,loss:4.168298244476318\n",
      "\t\t\tstep:1,loss:4.265270233154297\n",
      "\t\t\tstep:2,loss:4.263433456420898\n",
      "\t\t\tstep:3,loss:4.27157735824585\n",
      "\t\t\tstep:4,loss:4.280276298522949\n",
      "\t\t\tstep:5,loss:4.26577091217041\n",
      "\t\t\tstep:6,loss:4.260280132293701\n",
      "\t\t\tstep:7,loss:4.570485591888428\n",
      "\t\t\tstep:8,loss:4.359394550323486\n",
      "\t\t\tstep:9,loss:4.138807773590088\n"
     ]
    }
   ],
   "source": [
    "# training and infering\n",
    "num_steps=10001\n",
    "avg_loss=0\n",
    "\n",
    "enc_data_generator=DataGeneratorMT(batch_size,True)\n",
    "dec_data_generator=DataGeneratorMT(batch_size,False)\n",
    "print(\"started_training\")\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(10):\n",
    "    \n",
    "    #     defining the batch data.\n",
    "    batch_indexes=np.random.choice(train_inputs[1],batch_size)\n",
    "    enc_data,_,_,enc_lengths=enc_data_generator.unroll_batches(41,batch_indexes)\n",
    "    dec_data,dec_labels,_,dec_lengths=dec_data_generator.unroll_batches(61,batch_indexes)\n",
    "    dec_masks=np.zeros(shape=np.array(dec_data).shape)\n",
    "    #     getting the masks\n",
    "    for i,data in enumerate(dec_data):\n",
    "        dec_masks[i]=np.array([i for _ in range(batch_size)])<dec_lengths\n",
    "    \n",
    "    #     feeding in the placeholders.\n",
    "    feed_dict={\n",
    "        enc_train_inputs:enc_data,\n",
    "        dec_train_inputs:dec_data,\n",
    "        dec_train_labels:dec_labels,\n",
    "        enc_sequence_lengths:enc_lengths,\n",
    "        dec_labels_mask:dec_masks\n",
    "    }\n",
    "    \n",
    "    \n",
    "    if step<1000:\n",
    "        _,loss_value,predicted_value=sess.run([adam_optimize,loss,prediction],feed_dict=feed_dict)\n",
    "    else:\n",
    "        _,loss_value,predicted_value=sess.run([sgd_optimize,loss,prediction],feed_dict=feed_dict)\n",
    "    \n",
    "    print(\"\\t\\t\\tstep:{},loss:{}\".format(step,loss_value))\n",
    "    predicted_value=predicted_value.flatten()\n",
    "    avg_loss+=loss_value\n",
    "    \n",
    "    if not (step+1)%100:\n",
    "        print(\"\\t\\t step:\",step,\"\\t\\t\")\n",
    "        \n",
    "        print_str=\"Actual\"\n",
    "        \n",
    "        for word in np.concatenate(dec_labels,0)[::batch_size]:\n",
    "            print_str+=reverse_target_dictionary[word]+\" \"\n",
    "            if reverse_target_dictionary[word]==\"</s>\":\n",
    "                break\n",
    "        print(print_str)\n",
    "        \n",
    "        print(\"\\n\")\n",
    "        for word in predicted_value[::batch_size]:\n",
    "            print_str+=reverse_target_dictionary[word]+\" \"\n",
    "            if reverse_target_dictionary[word]==\"</s>\":\n",
    "                break\n",
    "        print(print_str)\n",
    "        \n",
    "        print(\"======================= average loss ====================\") \n",
    "        print(avg_loss/100)\n",
    "        \n",
    "        loss_over_time.append(avg_loss/100)\n",
    "        sess.run(inc_global_step)\n",
    "        avg_loss=0.0\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
